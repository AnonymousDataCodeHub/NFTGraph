{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import bidict\n",
    "\n",
    "def set_seed(seed=3407):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/data/sx/NFTGraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnodes = pd.read_csv(prefix+'/raw_data/nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = bidict.bidict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dfnodes[['addr','label']].to_numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(labels.shape[0]):\n",
    "    node_dict[i] = labels[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = dfnodes[['addr','OutCnt','OutAmount','OutValue','OutTransFee','InCnt','InAmount','InValue','InTransFee']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = node_features[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio, val_ratio = 0.4, 0.2\n",
    "\n",
    "nodes_anomaly = []\n",
    "nodes_non_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i][1]==1:\n",
    "        nodes_anomaly.append(i)\n",
    "    else:\n",
    "        nodes_non_anomaly.append(i)\n",
    "\n",
    "n = labels.shape[0]\n",
    "train_mask = torch.zeros(n).bool()\n",
    "val_mask = torch.zeros(n).bool()\n",
    "test_mask = torch.zeros(n).bool()\n",
    "\n",
    "import random\n",
    "random.shuffle(nodes_anomaly)\n",
    "train_ones = nodes_anomaly[:int(len(nodes_anomaly)*train_ratio)]\n",
    "val_ones = nodes_anomaly[int(len(nodes_anomaly)*train_ratio):int(len(nodes_anomaly)*(train_ratio+val_ratio))]\n",
    "test_ones = nodes_anomaly[int(len(nodes_anomaly)*(train_ratio+val_ratio)):]\n",
    "\n",
    "random.shuffle(nodes_non_anomaly)\n",
    "train_zeros = nodes_non_anomaly[:int(len(nodes_non_anomaly)*train_ratio)]\n",
    "val_zeros = nodes_non_anomaly[int(len(nodes_non_anomaly)*train_ratio):int(len(nodes_non_anomaly)*(train_ratio+val_ratio))]\n",
    "test_zeros = nodes_non_anomaly[int(len(nodes_non_anomaly)*(train_ratio+val_ratio)):]\n",
    "\n",
    "for i in train_ones+train_zeros:\n",
    "    train_mask[i] = True\n",
    "\n",
    "for i in val_ones+val_zeros:\n",
    "    val_mask[i] = True\n",
    "    \n",
    "for i in test_ones+test_zeros:\n",
    "    test_mask[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfedges = pd.read_csv(prefix+'/raw_data/edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = dfedges[['from','to']].to_numpy()\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edges = np.zeros_like(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(edges.shape[0]):\n",
    "    new_edges[i][0] = node_dict.inv[edges[i][0]]\n",
    "    new_edges[i][1] = node_dict.inv[edges[i][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.graph((new_edges[:,0].astype(int), new_edges[:,1].astype(int)))\n",
    "graph.ndata['train_mask'] = train_mask\n",
    "graph.ndata['val_mask'] = val_mask\n",
    "graph.ndata['test_mask'] = test_mask\n",
    "graph.ndata['label'] = torch.tensor(labels[:,1].astype(int))\n",
    "graph.ndata['feature'] = torch.tensor(features.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edata['timestamp'] = torch.tensor(dfedges['timestamp'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efeatures = dfedges[['TxnsCnt','transferedAmount','value','transactionFee']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edata['feature'] = torch.tensor(efeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl.save_graphs(prefix+'/datasets/dgl_graph/nftgraph', [graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "c = torch.stack([graph.edges()[0], graph.edges()[1]], dim=1).t().contiguous()\n",
    "\n",
    "data = Data(x=graph.ndata['feature'],edge_index=c,y=graph.ndata['label'],train_mask=graph.ndata['train_mask'],\\\n",
    "            val_mask=graph.ndata['val_mask'],test_mask=graph.ndata['test_mask'],\\\n",
    "            edge_attr=graph.edata['feature'],etime=graph.edata['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data,prefix+'/datasets/pyg_graph/nftgraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(prefix+'/datasets/pyg_graph/nftgraph')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.io import DatasetSaver\n",
    "from ogb.nodeproppred import NodePropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ogbn-nftgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = DatasetSaver(dataset_name = dataset_name,root=prefix+'/datasets/ogb_graph/submission', is_hetero = False, version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dict()\n",
    "labels = np.array(data.y)\n",
    "graph_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill dict\n",
    "g['num_nodes'] = int(data.num_nodes)\n",
    "g['node_feat'] = np.array(data.x) # axis = 1 is column!\n",
    "g['edge_index'] = np.array(data.edge_index)\n",
    "g['edge_feat'] = np.array(data.edge_attr)\n",
    "g['edge_time'] = np.array(data.etime)\n",
    "# saving a list of graphs\n",
    "graph_list.append(g)\n",
    "saver.save_graph_list(graph_list)\n",
    "saver.save_target_labels(labels.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = dict()\n",
    "num_data = len(labels)\n",
    "split_idx['train'] = data.train_mask.nonzero().squeeze()\n",
    "split_idx['valid'] = data.val_mask.nonzero().squeeze()\n",
    "split_idx['test'] = data.test_mask.nonzero().squeeze()\n",
    "saver.save_split(split_idx, split_name = 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_path = prefix+'/datasets/mapping'\n",
    "os.makedirs(mapping_path,exist_ok=True)\n",
    "try:\n",
    "    os.mknod(os.path.join(mapping_path, 'README.md'))\n",
    "except:\n",
    "    print(\"Readme.md already exists.\")\n",
    "saver.copy_mapping_dir(mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save_task_info(task_type = 'binary classification', eval_metric = 'rocauc', num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = saver.get_meta_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.zip()\n",
    "saver.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = prefix+'/datasets/ogb_graph/submission_ogbn_nftgraph/nftgraph.zip'\n",
    "dstdirs = prefix+'/datasets/ogb_graph/submission_ogbn_nftgraph/nftgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip $filedir -d $dstdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NodePropPredDataset(dataset_name,root=prefix+'/dataset/',meta_dict = meta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_edge = dataset.get_idx_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.io import DatasetSaver\n",
    "from ogb.linkproppred import LinkPropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ogbl-nftgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = DatasetSaver(dataset_name = dataset_name,root=prefix+'/datasets/ogb_graph/submission', is_hetero = False, version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset: {dataset_name}:')\n",
    "print('======================')\n",
    "print(f'data: {data}')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.edge_index.shape[1]}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.has_self_loops()}')\n",
    "print(f'Is directed: {data.is_directed()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = []\n",
    "\n",
    "graph = dict()\n",
    "graph['num_nodes'] = int(data.num_nodes)\n",
    "graph['node_feat'] = np.array(data.x)\n",
    "graph['edge_index'] = data.edge_index.numpy() # only train pos edge index, but both directions / undirected!\n",
    "graph['edge_feat'] = data.edge_attr.numpy()\n",
    "graph_list.append(graph)\n",
    "\n",
    "print(graph_list)\n",
    "# saving a list of graphs\n",
    "saver.save_graph_list(graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def custom_train_test_split_edges(data, val_ratio: float = 0.05, test_ratio: float = 0.1):\n",
    "    r\"\"\"Splits the edges of a :class:`torch_geometric.data.Data` object\n",
    "    into positive and negative train/val/test edges.\n",
    "    As such, it will replace the :obj:`edge_index` attribute with\n",
    "    :obj:`train_pos_edge_index`, :obj:`train_pos_neg_adj_mask`,\n",
    "    :obj:`val_pos_edge_index`, :obj:`val_neg_edge_index` and\n",
    "    :obj:`test_pos_edge_index` attributes.\n",
    "    If :obj:`data` has edge features named :obj:`edge_attr`, then\n",
    "    :obj:`train_pos_edge_attr`, :obj:`val_pos_edge_attr` and\n",
    "    :obj:`test_pos_edge_attr` will be added as well.\n",
    "\n",
    "    Args:\n",
    "        data (Data): The data object.\n",
    "        val_ratio (float, optional): The ratio of positive validation edges.\n",
    "            (default: :obj:`0.05`)\n",
    "        test_ratio (float, optional): The ratio of positive test edges.\n",
    "            (default: :obj:`0.1`)\n",
    "\n",
    "    :rtype: :class:`torch_geometric.data.Data`\n",
    "    \"\"\"\n",
    "\n",
    "    assert 'batch' not in data  # No batch-mode.\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    original_edge_index = data.edge_index\n",
    "    row, col = data.edge_index\n",
    "    edge_attr = data.edge_attr\n",
    "    data.edge_index = data.edge_attr = None\n",
    "\n",
    "    # Return upper triangular portion.\n",
    "    mask = row < col\n",
    "    row, col = row[mask], col[mask]\n",
    "\n",
    "    if edge_attr is not None:\n",
    "        edge_attr = edge_attr[mask]\n",
    "\n",
    "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
    "    n_t = int(math.floor(test_ratio * row.size(0)))\n",
    "\n",
    "    # Positive edges.\n",
    "    perm = torch.randperm(row.size(0))\n",
    "    row, col = row[perm], col[perm]\n",
    "    if edge_attr is not None:\n",
    "        edge_attr = edge_attr[perm]\n",
    "\n",
    "    r, c = row[:n_v], col[:n_v]\n",
    "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    if edge_attr is not None:\n",
    "        data.val_pos_edge_attr = edge_attr[:n_v]\n",
    "\n",
    "    r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\n",
    "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    if edge_attr is not None:\n",
    "        data.test_pos_edge_attr = edge_attr[n_v:n_v + n_t]\n",
    "\n",
    "    r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
    "\n",
    "    # this section is custom\n",
    "    # -----------------------\n",
    "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "\n",
    "    helper = data.train_pos_edge_index\n",
    "\n",
    "    # if edge_attr is not None:\n",
    "    #     out = to_undirected(data.train_pos_edge_index, edge_attr[n_v + n_t:])\n",
    "    #     data.edge_index, data.edge_attr = out\n",
    "    # else:\n",
    "    #     data.edge_index = to_undirected(data.train_pos_edge_index)\n",
    "\n",
    "    data.train_pos_edge_index = helper\n",
    "\n",
    "    if edge_attr is not None:\n",
    "        data.train_pos_edge_attr = edge_attr[n_v + n_t:]\n",
    "    # -----------------------\n",
    "\n",
    "    data.edge_index = original_edge_index\n",
    "\n",
    "    \n",
    "    # generate negative edge list by randomly sampling the nodes!\n",
    "    neg_edge_list = np.array(np.random.randint(low=0, high=num_nodes,\n",
    "                                               size=(2*data.edge_index.shape[1],)). # left and right edge - 2x, to be safe:3.4\n",
    "                             reshape((data.edge_index.shape[1],2)))\n",
    "\n",
    "    a = np.min(neg_edge_list, axis=1)\n",
    "    b = np.max(neg_edge_list, axis=1)\n",
    "\n",
    "    neg_edge_list = np.vstack((a,b)).transpose()\n",
    "\n",
    "    # filter for unique edges in the negative edge list\n",
    "\n",
    "    # obtain the indexes of the first occuring objects\n",
    "    # _, indices = np.unique(edges[:,[0,1]],return_index=True,axis=0)\n",
    "    _, indices = np.unique(neg_edge_list[:,[0,1]],return_index=True,axis=0)\n",
    "\n",
    "    neg_edge_list = neg_edge_list[indices]\n",
    "\n",
    "    all_edges = np.concatenate((np.array(data.edge_index.t()),neg_edge_list), axis=0) # concat positive edges of graph and negative edges\n",
    "\n",
    "    # obtain the indexes of unique objects\n",
    "    _, indices = np.unique(all_edges[:, [0, 1]], return_index=True, axis=0)\n",
    "\n",
    "    # sort indices\n",
    "\n",
    "    indices = np.sort(indices)\n",
    "    indices = indices[indices > data.edge_index.shape[1]] # remove the indices of the positive edges!\n",
    "    neg_edge_list = torch.tensor(all_edges[indices])\n",
    "\n",
    "    # sample edges according to percentage\n",
    "\n",
    "    ind = torch.randperm(neg_edge_list.shape[0])\n",
    "\n",
    "    data.val_neg_edge_index = neg_edge_list[ind[:n_v]].t()\n",
    "    data.test_neg_edge_index = neg_edge_list[ind[n_v:n_v+n_t]].t()\n",
    "    data.train_neg_edge_index = neg_edge_list[ind[n_v+n_t:n_v+n_t+data.train_pos_edge_index.shape[1]]].t()\n",
    "\n",
    "    \"\"\"\n",
    "    #Original Sampling: allocates to much memory\n",
    "\n",
    "    # Negative edges.\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    neg_adj_mask[row, col] = 0\n",
    "\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero(as_tuple=False).t()\n",
    "    ind = torch.randperm(neg_row.size(0))\n",
    "    perm = ind[:n_v + n_t]\n",
    "    perm_train = ind[n_v+n_t:n_v+n_t+data.train_pos_edge_index.shape[1]]\n",
    "    neg_row_train, neg_col_train = neg_row[perm_train], neg_col[perm_train]\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "    neg_adj_mask[neg_row, neg_col] = 0\n",
    "    data.train_neg_adj_mask = neg_adj_mask\n",
    "\n",
    "    row, col = neg_row[:n_v], neg_col[:n_v]\n",
    "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\n",
    "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    row, col = neg_row_train , neg_col_train\n",
    "    data.train_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "    \"\"\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "test_ratio = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = custom_train_test_split_edges(data, val_ratio=val_ratio, test_ratio = test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data.train_mask,data.val_mask,data.test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_edge = {'train': {}, 'valid': {}, 'test': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_edge['train']['edge'] = data.train_pos_edge_index.t() # these are only one directional\n",
    "split_edge['train']['edge_neg'] = data.train_neg_edge_index.t() # these are only one directional\n",
    "split_edge['valid']['edge'] = data.val_pos_edge_index.t() # these are only one directional\n",
    "split_edge['valid']['edge_neg'] = data.val_neg_edge_index.t()  # these are only one directional\n",
    "split_edge['test']['edge'] = data.test_pos_edge_index.t()  # these are only one directional\n",
    "split_edge['test']['edge_neg'] = data.test_neg_edge_index.t()  # these are only one directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_edge['train']['edge_attr'] = data.train_pos_edge_attr.t() # these are only one directional\n",
    "split_edge['test']['edge_attr'] = data.test_pos_edge_attr.t() # these are only one directional\n",
    "split_edge['valid']['edge_attr'] = data.val_pos_edge_attr.t() # these are only one directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save_split(split_edge, split_name = 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_path = prefix+'/mapping/'\n",
    "\n",
    "# prepare mapping information first and store it under this directory (empty below).\n",
    "os.makedirs(mapping_path,exist_ok=True)\n",
    "try:\n",
    "    os.mknod(os.path.join(mapping_path, 'README.md'))\n",
    "except:\n",
    "    print(\"Readme.md already exists.\")\n",
    "saver.copy_mapping_dir(mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save_task_info(task_type = 'link prediction', eval_metric = 'mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = saver.get_meta_dict()\n",
    "print(meta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.zip()\n",
    "saver.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = prefix+'/datasets/ogb_graph/submission_ogbl_nftgraph/nftgraph.zip'\n",
    "dstdirs = prefix+'/datasets/ogb_graph/submission_ogbl_nftgraph/nftgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip $filedir -d $dstdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LinkPropPredDataset(dataset_name,root=prefix+'/datasets/', meta_dict = meta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgb_edges = dfedges[['timestamp','from','to','TxnsCnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgb_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgb_edges.to_csv(prefix+'/datasets/tgb_graph/tgbl_nftgraph/tgbl-nftgraph_edgelist.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
